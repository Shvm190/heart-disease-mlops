# Heart Disease Prediction - MLOps Project

This project implements a production-ready MLOps pipeline for heart disease risk classification, featuring experiment tracking, containerization, and Kubernetes orchestration.

# Architechture Diagram

```mermaid
graph TB
    A[Data Source] -->|Download| B[Data Processing]
    B -->|Clean & Transform| C[Feature Engineering]
    C -->|Train| D[Model Training]
    D -->|Log| E[MLflow Tracking]
    D -->|Save| F[Model Registry]
    F -->|Package| G[Docker Container]
    G -->|Deploy| H[Kubernetes]
    H -->|Expose| I[Load Balancer]
    I -->|Serve| J[API Endpoint]
    J -->|Monitor| K[Prometheus]
    K -->|Visualize| L[Grafana]
    M[GitHub] -->|Trigger| N[CI/CD Pipeline]
    N -->|Build & Test| G
```


# Project Structure
```
heart-disease-mlops/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # Raw dataset
â”‚   â”œâ”€â”€ processed/                    # Processed data
â”‚   â””â”€â”€ download_data.py              # Script to download dataset
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb                  # Exploratory Data Analysis
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb  # Feature engineering experiments
â”‚   â””â”€â”€ 03_model_training.ipynb       # Model training experiments
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                     # Configuration management
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_loader.py            # Data loading utilities
â”‚   â”‚   â””â”€â”€ preprocessing.py          # Data preprocessing pipeline
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ feature_engineering.py    # Feature transformation
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ train.py                  # Model training
â”‚   â”‚   â”œâ”€â”€ predict.py                # Model prediction
â”‚   â”‚   â””â”€â”€ evaluate.py               # Model evaluation
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ logger.py                 # Logging utilities
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                        # FastAPI application
â”‚   â””â”€â”€ schemas.py                    # Pydantic models for API
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_data_preprocessing.py    # Data processing tests
â”‚   â”œâ”€â”€ test_model.py                 # Model tests
â”‚   â””â”€â”€ test_api.py                   # API tests
â”‚
â”œâ”€â”€ mlruns/                           # MLflow tracking directory
â”‚
â”œâ”€â”€ models/                           # Saved models
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ kubernetes/
â”‚   â”‚   â”œâ”€â”€ deployment.yaml           # K8s deployment
â”‚   â”‚   â”œâ”€â”€ service.yaml              # K8s service
â”‚   â”‚   â””â”€â”€ ingress.yaml              # K8s ingress
â”‚   â”œâ”€â”€ helm/
â”‚   â”‚   â””â”€â”€ heart-disease-chart/      # Helm chart
â”‚   â””â”€â”€ docker-compose.yml            # Local deployment
â”‚
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus.yml                # Prometheus config
â”‚   â””â”€â”€ grafana-dashboard.json        # Grafana dashboard
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci-cd.yml                 # GitHub Actions pipeline
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_model.py                # Training script
â”‚   â”œâ”€â”€ test_api.sh                   # API testing script
â”‚   â””â”€â”€ build_docker.sh               # Docker build script
â”‚
â”œâ”€â”€ screenshots/                      # Screenshots for report
â”‚
â”œâ”€â”€ Dockerfile                        # Docker configuration
â”œâ”€â”€ docker-compose.yml                # Docker Compose setup
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ setup.py                          # Package setup
â”œâ”€â”€ .env.example                      # Environment variables template
â”œâ”€â”€ .gitignore                        # Git ignore rules
â”œâ”€â”€ .dockerignore                     # Docker ignore rules
â”œâ”€â”€ pytest.ini                        # Pytest configuration
â”œâ”€â”€ README.md                         # Project documentation
â””â”€â”€ REPORT.md                         # Assignment report
```

## ğŸš€ Quick Start (Local Development)

1. **Environment Setup**:
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

```


2. **Data & Training**:
```bash
python data/download_data.py
python scripts/train_model.py

```


*Note: View training logs and metrics via `mlflow ui`.*
3. **Run API**:
```bash
uvicorn api.app:app --host 0.0.0.0 --port 8000

```

4. Initialize Dashboards
Run the load generation script to send 500 randomized requests to the API. This simulates real-world usage and populates the Prometheus metrics.

```bash
# Ensure your API is accessible at localhost:8000
# (via uvicorn, docker-compose, or kubectl port-forward)

chmod +x scripts/generate_traffic.sh
./scripts/generate_traffic.sh
```

---

## ğŸ³ Containerization & Monitoring

To run the full stack (API + Prometheus + Grafana) using Docker:

```bash
docker-compose up --build -d

```

* **API**: http://localhost:8000
* **Prometheus**: http://localhost:9090
* **Grafana**: http://localhost:3000 (Credentials: `admin`/`admin`)

**Initialize Dashboards**
Run the load generation script to send 500 randomized requests to the API. This simulates real-world usage and populates the Prometheus metrics.

```bash
# Ensure your API is accessible at localhost:8000
# (via uvicorn, docker-compose, or kubectl port-forward)

chmod +x scripts/generate_traffic.sh
./scripts/generate_traffic.sh
```

---

## â˜¸ï¸ Kubernetes Deployment (Minikube)

To deploy the production-grade manifest with Horizontal Pod Autoscaling (HPA):

1. **Start Cluster & Point Docker Shell**:
```bash
minikube start
eval $(minikube docker-env)

```


2. **Build Image Locally**:
```bash
docker build -t heart-disease-api:latest .

```


3. **Deploy Manifests**:
```bash
kubectl apply -f deployment/kubernetes/deployment.yaml

```


4. **Access the API**:
```bash
kubectl port-forward service/heart-disease-api-service 8000:80

```

5. Initialize Dashboards
Run the load generation script to send 500 randomized requests to the API. This simulates real-world usage and populates the Prometheus metrics.

```bash
# Ensure your API is accessible at localhost:8000
# (via uvicorn, docker-compose, or kubectl port-forward)

chmod +x scripts/generate_traffic.sh
./scripts/generate_traffic.sh
```


---

## ğŸ§ª Testing & Validation

Run the suite of unit tests for preprocessing and API endpoints:

```bash
pytest tests/

```

To simulate production load and verify the HPA/Monitoring:

```bash
chmod +x scripts/generate_traffic.sh
./scripts/generate_traffic.sh

```

---

## ğŸ“Š Project Artifacts

* **Model Registry**: MLflow tracking for LR and Random Forest models.
* **Infrastructure**: Kubernetes Deployment with Liveness/Readiness probes.
* **Metrics**: Custom Prometheus exporters for model drift and prediction confidence.

